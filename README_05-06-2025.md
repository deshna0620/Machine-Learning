# Manual K-Fold Cross-Validation with Logistic Regression

## Overview

This project performs a manual implementation of **K-Fold Cross-Validation (K=5)** using the **Wine dataset** from `sklearn.datasets`. A **Logistic Regression** model is trained and evaluated on each fold, and the accuracy is computed per fold and averaged. The performance across all folds is also visualized.

## File Structure

- `05-06-2025.py`: Main Python script that loads the dataset, performs manual K-Fold cross-validation, trains the model, evaluates accuracy, and generates a plot.
- `fold_accuracies_05-06-2025.png`: Bar chart showing accuracy for each fold and average accuracy (saved automatically when the script is run).

## Dataset

- **Source**: `sklearn.datasets.load_wine()`
- **Type**: Multiclass classification
- **Target**: Wine categories (0, 1, 2)

## Steps Performed

1. Load the Wine dataset.
2. Shuffle and split data manually into 5 equal folds.
3. For each fold:
   - Use 4 folds for training and 1 fold for testing.
   - Train a Logistic Regression model.
   - Predict and evaluate accuracy.
4. Print accuracy for each fold.
5. Print average accuracy across all folds.
6. Plot and save a bar chart of fold-wise accuracy.

## How to Run

Make sure you have the required libraries installed:
pip install numpy scikit-learn matplotlib

Run the script:
python 05-06-2025.py

## Output

- Printed accuracy values for each fold.
- Printed average accuracy.
- Plot saved as `fold_accuracies_05-06-2025.png`.

## Example Output
Fold 1 Accuracy: 0.8889
Fold 2 Accuracy: 0.8889
Fold 3 Accuracy: 0.9714
Fold 4 Accuracy: 0.8889
Fold 5 Accuracy: 0.9143

Average Accuracy: 0.9107

A bar chart will also be displayed and saved to the working directory.
