# SVM Classification on Digits Dataset

This project involves training a Support Vector Machine (SVM) model to classify handwritten digits (0â€“9) using the `load_digits` dataset from `scikit-learn`. The model's performance is evaluated using various classification metrics.

## Dataset

- **Source**: `sklearn.datasets.load_digits`
- **Description**: The dataset contains 1,797 samples of 8x8 images representing handwritten digits from 0 to 9. Each image is flattened into a 64-dimensional vector.

## Objective

To train an SVM classifier to correctly identify digits and evaluate its performance using the following metrics:

- Accuracy
- Precision
- Recall
- F1-Score
- ROC-AUC (One-vs-Rest)
- Confusion Matrix

## Steps Followed

1. Load the digits dataset
2. Preprocess the data (standardization and label binarization)
3. Split the dataset into training and testing sets
4. Train a Support Vector Machine classifier (`SVC`)
5. Evaluate the model with:
    - Accuracy
    - Confusion Matrix
    - Classification Report (Precision, Recall, F1)
    - ROC-AUC (using One-vs-Rest strategy)
6. Visualize the Confusion Matrix using a heatmap

## Libraries Used

- `scikit-learn`
- `matplotlib`
- `seaborn`

## How to Run

1. Install the required libraries if not already installed:
pip install scikit-learn matplotlib seaborn
2. Save the Python code in a file, e.g., `02-06-2025.py`.
3. Run the script:
python 02-06-2025.py

## Output

* **Text Output**:

  * Classification Report
  * Accuracy Score
  * ROC-AUC Score (using One-vs-Rest)
* **Visualization**:

  * Confusion Matrix plotted using `seaborn.heatmap`

## Notes

* The `SVC` model is used with an RBF kernel and `probability=True` to enable ROC-AUC score computation.
* ROC-AUC is computed in a multi-class setting using the One-vs-Rest (OvR) approach.
* Data is standardized using `StandardScaler` for optimal SVM performance.
